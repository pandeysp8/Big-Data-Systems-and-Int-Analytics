{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.4\n",
      "  Downloading https://files.pythonhosted.org/packages/99/72/a420e22dc93416d30981e87a2318823ec09a9b18631369df0e7d9d164073/tensorflow-1.4.0-cp27-cp27mu-manylinux1_x86_64.whl (40.7MB)\n",
      "Requirement already satisfied, skipping upgrade: enum34>=1.1.6 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.4) (1.1.6)\n",
      "Requirement already satisfied, skipping upgrade: backports.weakref>=1.0rc1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.4) (1.0.post1)\n",
      "Requirement already satisfied, skipping upgrade: wheel in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.4) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: mock>=2.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.4) (2.0.0)\n",
      "Collecting tensorflow-tensorboard<0.5.0,>=0.4.0rc1 (from tensorflow==1.4)\n",
      "  Downloading https://files.pythonhosted.org/packages/64/cd/f3d14d441eb1c5228aaf7e12e8e94895ae73e9af50383e481610b34357bd/tensorflow_tensorboard-0.4.0-py2-none-any.whl (1.7MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.12.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.4) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.3.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.4) (3.13.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow==1.4) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: funcsigs>=1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow==1.4) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pbr>=0.11 in /usr/local/envs/py2env/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow==1.4) (5.5.0)\n",
      "Collecting bleach==1.5.0 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4)\n",
      "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: futures>=3.1.1; python_version < \"3.2\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4) (2.6.11)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in /usr/local/envs/py2env/lib/python2.7/site-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4) (1.0.1)\n",
      "Collecting html5lib==0.9999999 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4)\n",
      "  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/envs/py2env/lib/python2.7/site-packages (from protobuf>=3.3.0->tensorflow==1.4) (44.0.0.post20200106)\n",
      "Requirement already satisfied, skipping upgrade: ordereddict in /usr/local/envs/py2env/lib/python2.7/site-packages (from funcsigs>=1->mock>=2.0.0->tensorflow==1.4) (1.1)\n",
      "Building wheels for collected packages: html5lib\n",
      "  Running setup.py bdist_wheel for html5lib: started\n",
      "  Running setup.py bdist_wheel for html5lib: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
      "Successfully built html5lib\n",
      "Installing collected packages: html5lib, bleach, tensorflow-tensorboard, tensorflow\n",
      "  Found existing installation: html5lib 1.1\n",
      "    Uninstalling html5lib-1.1:\n",
      "      Successfully uninstalled html5lib-1.1\n",
      "  Found existing installation: bleach 2.1.2\n",
      "    Uninstalling bleach-2.1.2:\n",
      "      Successfully uninstalled bleach-2.1.2\n",
      "  Found existing installation: tensorflow 1.8.0\n",
      "    Uninstalling tensorflow-1.8.0:\n",
      "      Successfully uninstalled tensorflow-1.8.0\n",
      "Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorflow-1.4.0 tensorflow-tensorboard-0.4.0\n",
      "Collecting pytz==2018.4\n",
      "  Downloading https://files.pythonhosted.org/packages/dc/83/15f7833b70d3e067ca91467ca245bae0f6fe56ddc7451aa0dc5606b120f2/pytz-2018.4-py2.py3-none-any.whl (510kB)\n",
      "Installing collected packages: pytz\n",
      "Successfully installed pytz-2018.4\n",
      "Uninstalling google-cloud-dataflow-2.0.0:\n",
      "  Successfully uninstalled google-cloud-dataflow-2.0.0\n",
      "Collecting apache-beam[gcp]==2.6\n",
      "  Downloading https://files.pythonhosted.org/packages/26/44/38642c061f1f1d1ffc166e452f74ec1cc5d14be5afccc0b970af5be34828/apache_beam-2.6.0-cp27-cp27mu-manylinux1_x86_64.whl (2.3MB)\n",
      "Requirement already satisfied, skipping upgrade: dill<=0.2.8.2,>=0.2.6 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.6) (0.2.6)\n",
      "Collecting pydot<1.3,>=1.2.0 (from apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/f1/e61d6dfe6c1768ed2529761a68f70939e2569da043e9f15a8d84bf56cadf/pydot-1.2.4.tar.gz (132kB)\n",
      "Requirement already satisfied, skipping upgrade: oauth2client<5,>=2.0.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.6) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: mock<3.0.0,>=1.0.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.6) (2.0.0)\n",
      "Collecting typing<3.7.0,>=3.6.0 (from apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/3e/29f92b7aeda5b078c86d14f550bf85cff809042e3429ace7af6193c3bc9f/typing-3.6.6-py2-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: pyyaml<4.0.0,>=3.12 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.6) (3.13)\n",
      "Collecting pyvcf<0.7.0,>=0.6.8 (from apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/20/b6/36bfb1760f6983788d916096193fc14c83cce512c7787c93380e09458c09/PyVCF-0.6.8.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: future<1.0.0,>=0.16.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.6) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: avro<2.0.0,>=1.8.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.6) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: crcmod<2.0,>=1.7 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.6) (1.7)\n",
      "Collecting httplib2<=0.11.3,>=0.8 (from apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/ce/aa4a385e3e9fd351737fd2b07edaa56e7a730448465aceda6b35086a0d9b/httplib2-0.11.3.tar.gz (215kB)\n",
      "Collecting fastavro==0.19.7 (from apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/0a/b08ba5cef63c675e8442c2bf1cbcef90c8b9f824be2202d492f0cedb0913/fastavro-0.19.7.tar.gz (499kB)\n",
      "Requirement already satisfied, skipping upgrade: futures<4.0.0,>=3.1.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.6) (3.2.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio<2,>=1.8 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.6) (1.31.0)\n",
      "Requirement already satisfied, skipping upgrade: six<1.12,>=1.9 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.6) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf<4,>=3.5.0.post1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.6) (3.13.0)\n",
      "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/8b/bb/ce76b7eb315b4d409eafa8c1e89514a1e34a75726fba64940521ad3a855c/hdfs-2.6.0.tar.gz (43kB)\n",
      "Requirement already satisfied, skipping upgrade: pytz<=2018.4,>=2018.3 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.6) (2018.4)\n",
      "Collecting google-apitools<=0.5.20,>=0.5.18; extra == \"gcp\" (from apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/0c/64f84f91643f775fdb64c6c10f4a4f0d827f8b0d98a2ba2b4bb9dc2f8646/google_apitools-0.5.20-py2-none-any.whl (330kB)\n",
      "Collecting proto-google-cloud-pubsub-v1==0.15.4; extra == \"gcp\" (from apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/a2/2eeffa0069830f00016196dfdd69491cf562372b5353f2e8e378b3c2cb0a/proto-google-cloud-pubsub-v1-0.15.4.tar.gz\n",
      "Collecting google-cloud-bigquery==0.25.0; extra == \"gcp\" (from apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/67/6165c516ff6ceaa62eb61f11d8451e1b0acc4d3775e181630aba9652babb/google_cloud_bigquery-0.25.0-py2.py3-none-any.whl (41kB)\n",
      "Collecting google-cloud-pubsub==0.26.0; extra == \"gcp\" (from apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/37/92/c74a643126d58505daec9addf872dfaffea3305981b90cc435f4b9213cdd/google_cloud_pubsub-0.26.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: googledatastore==7.0.1; extra == \"gcp\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.6) (7.0.1)\n",
      "Requirement already satisfied, skipping upgrade: proto-google-cloud-datastore-v1<=0.90.4,>=0.90.0; extra == \"gcp\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.6) (0.90.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.1.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from pydot<1.3,>=1.2.0->apache-beam[gcp]==2.6) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.7 in /usr/local/envs/py2env/lib/python2.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]==2.6) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.0.5 in /usr/local/envs/py2env/lib/python2.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]==2.6) (0.2.7)\n",
      "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]==2.6) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: funcsigs>=1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]==2.6) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pbr>=0.11 in /usr/local/envs/py2env/lib/python2.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]==2.6) (5.5.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/envs/py2env/lib/python2.7/site-packages (from pyvcf<0.7.0,>=0.6.8->apache-beam[gcp]==2.6) (44.0.0.post20200106)\n",
      "Requirement already satisfied, skipping upgrade: enum34>=1.0.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from grpcio<2,>=1.8->apache-beam[gcp]==2.6) (1.1.6)\n",
      "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/55/8f8cab2afd404cf578136ef2cc5dfb50baa1761b68c9da1fb1e4eed343c9/docopt-0.6.2.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.7.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.6) (2.18.4)\n",
      "Collecting fasteners>=0.14 (from google-apitools<=0.5.20,>=0.5.18; extra == \"gcp\"->apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/31/91/6630ebd169ca170634ca8a10dfcc5f5c11b0621672d4c2c9e40381c6d81a/fasteners-0.16.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: googleapis-common-protos<2.0dev,>=1.5.2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from proto-google-cloud-pubsub-v1==0.15.4; extra == \"gcp\"->apache-beam[gcp]==2.6) (1.6.0)\n",
      "Collecting google-cloud-core<0.26dev,>=0.25.0 (from google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/dd/00e90bd1f6788f06ca5ea83a0ec8dd76350b38303bb8f09d2bf692eb1294/google_cloud_core-0.25.0-py2.py3-none-any.whl (52kB)\n",
      "Collecting gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0 (from google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a7/0225bd7a95e037a0afa90b2dd9534d0c79cd62283a5bddb30a3197579cbc/gapic-google-cloud-pubsub-v1-0.15.4.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: ordereddict in /usr/local/envs/py2env/lib/python2.7/site-packages (from funcsigs>=1->mock<3.0.0,>=1.0.1->apache-beam[gcp]==2.6) (1.1)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.6) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.6) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.6) (1.22)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.6) (2019.11.28)\n",
      "Collecting monotonic>=0.1; python_version < \"3.4\" (from fasteners>=0.14->google-apitools<=0.5.20,>=0.5.18; extra == \"gcp\"->apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/9a/67/7e8406a29b6c45be7af7740456f7f37025f0506ae2e05fb9009a53946860/monotonic-1.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: google-auth-httplib2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-core<0.26dev,>=0.25.0->google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]==2.6) (0.0.4)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2.0.0dev,>=0.4.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-core<0.26dev,>=0.25.0->google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]==2.6) (1.21.1)\n",
      "Collecting google-gax<0.16dev,>=0.15.7 (from gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0->google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/b4/ff312fa42f91535c67567c1d08e972db0e7c548e9a63c6f3bcc5213b32fc/google_gax-0.15.16-py2.py3-none-any.whl (46kB)\n",
      "Collecting grpc-google-iam-v1<0.12dev,>=0.11.1 (from gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0->google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/28/f26f67381cb23e81271b8d66c00a846ad9d25a909ae1ae1df8222fad2744/grpc-google-iam-v1-0.11.4.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-cloud-core<0.26dev,>=0.25.0->google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]==2.6) (3.1.1)\n",
      "Collecting ply==3.8 (from google-gax<0.16dev,>=0.15.7->gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0->google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]==2.6)\n",
      "  Downloading https://files.pythonhosted.org/packages/96/e0/430fcdb6b3ef1ae534d231397bee7e9304be14a47a267e82ebcb3323d0b5/ply-3.8.tar.gz (157kB)\n",
      "Building wheels for collected packages: pydot, pyvcf, httplib2, fastavro, hdfs, proto-google-cloud-pubsub-v1, docopt, gapic-google-cloud-pubsub-v1, grpc-google-iam-v1, ply\n",
      "  Running setup.py bdist_wheel for pydot: started\n",
      "  Running setup.py bdist_wheel for pydot: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/6a/a5/14/25541ebcdeaf97a37b6d05c7ff15f5bd20f5e91b99d313e5b4\n",
      "  Running setup.py bdist_wheel for pyvcf: started\n",
      "  Running setup.py bdist_wheel for pyvcf: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/81/91/41/3272543c0b9c61da9c525f24ee35bae6fe8f60d4858c66805d\n",
      "  Running setup.py bdist_wheel for httplib2: started\n",
      "  Running setup.py bdist_wheel for httplib2: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/1b/9c/9e/1f6fdb21dbb1fe6a99101d697f12cb8c1fa96c1587df69adba\n",
      "  Running setup.py bdist_wheel for fastavro: started\n",
      "  Running setup.py bdist_wheel for fastavro: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/eb/5a/3e/3c2f0642da6a98b89f8ba910caee749af59a1ee4f1cde02f5b\n",
      "  Running setup.py bdist_wheel for hdfs: started\n",
      "  Running setup.py bdist_wheel for hdfs: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/50/3e/59/66d59691485550103f7c957d9cd1ff6471232453bf31c053c3\n",
      "  Running setup.py bdist_wheel for proto-google-cloud-pubsub-v1: started\n",
      "  Running setup.py bdist_wheel for proto-google-cloud-pubsub-v1: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/d1/0d/9e/95e7192ab2625847ac40b2bc618800bf5b6c984cd572a83314\n",
      "  Running setup.py bdist_wheel for docopt: started\n",
      "  Running setup.py bdist_wheel for docopt: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/9b/04/dd/7daf4150b6d9b12949298737de9431a324d4b797ffd63f526e\n",
      "  Running setup.py bdist_wheel for gapic-google-cloud-pubsub-v1: started\n",
      "  Running setup.py bdist_wheel for gapic-google-cloud-pubsub-v1: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/f4/2b/10/bdcbc9be2ae4e437232e118056f026025cf2cc46d6dcf0d69d\n",
      "  Running setup.py bdist_wheel for grpc-google-iam-v1: started\n",
      "  Running setup.py bdist_wheel for grpc-google-iam-v1: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/b6/c6/31/c20321a5a3fde456fc375b7c2814135e6e98bc0d74c40239d9\n",
      "  Running setup.py bdist_wheel for ply: started\n",
      "  Running setup.py bdist_wheel for ply: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/f2/21/c0/f0056cc96847933daa961a19eb59a2ecd0228fdbe3376e7a68\n",
      "Successfully built pydot pyvcf httplib2 fastavro hdfs proto-google-cloud-pubsub-v1 docopt gapic-google-cloud-pubsub-v1 grpc-google-iam-v1 ply\n",
      "Installing collected packages: pydot, typing, pyvcf, httplib2, fastavro, docopt, hdfs, monotonic, fasteners, google-apitools, proto-google-cloud-pubsub-v1, google-cloud-core, google-cloud-bigquery, ply, google-gax, grpc-google-iam-v1, gapic-google-cloud-pubsub-v1, google-cloud-pubsub, apache-beam\n",
      "  Found existing installation: httplib2 0.18.1\n",
      "    Uninstalling httplib2-0.18.1:\n",
      "      Successfully uninstalled httplib2-0.18.1\n",
      "  Found existing installation: google-apitools 0.5.10\n",
      "    Uninstalling google-apitools-0.5.10:\n",
      "      Successfully uninstalled google-apitools-0.5.10\n",
      "  Found existing installation: google-cloud-core 0.28.1\n",
      "    Uninstalling google-cloud-core-0.28.1:\n",
      "      Successfully uninstalled google-cloud-core-0.28.1\n",
      "  Found existing installation: google-cloud-bigquery 0.23.0\n",
      "    Uninstalling google-cloud-bigquery-0.23.0:\n",
      "      Successfully uninstalled google-cloud-bigquery-0.23.0\n",
      "Successfully installed apache-beam-2.6.0 docopt-0.6.2 fastavro-0.19.7 fasteners-0.16.3 gapic-google-cloud-pubsub-v1-0.15.4 google-apitools-0.5.20 google-cloud-bigquery-0.25.0 google-cloud-core-0.25.0 google-cloud-pubsub-0.26.0 google-gax-0.15.16 grpc-google-iam-v1-0.11.4 hdfs-2.6.0 httplib2-0.11.3 monotonic-1.6 ply-3.8 proto-google-cloud-pubsub-v1-0.15.4 pydot-1.2.4 pyvcf-0.6.8 typing-3.6.6\n",
      "Collecting google-cloud-bigquery==0.23.0\n",
      "  Downloading https://files.pythonhosted.org/packages/78/9b/b05638d407d84ac12acfd6d7a4cad92c55abb567630de94581cfda495ffb/google_cloud_bigquery-0.23.0-py2.py3-none-any.whl (77kB)\n",
      "Collecting google-cloud-core<0.24dev,>=0.23.1 (from google-cloud-bigquery==0.23.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/59/3d/20d925c47d20094b0f1c69a7613ca547385a3da50df4274d7e36bfb4c078/google_cloud_core-0.23.1-py2.py3-none-any.whl (85kB)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.3.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-core<0.24dev,>=0.23.1->google-cloud-bigquery==0.23.0) (1.6.0)\n",
      "Requirement already satisfied: six in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-core<0.24dev,>=0.23.1->google-cloud-bigquery==0.23.0) (1.10.0)\n",
      "Requirement already satisfied: google-auth-httplib2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-core<0.24dev,>=0.23.1->google-cloud-bigquery==0.23.0) (0.0.4)\n",
      "Requirement already satisfied: google-auth<2.0.0dev,>=0.4.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-core<0.24dev,>=0.23.1->google-cloud-bigquery==0.23.0) (1.21.1)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-core<0.24dev,>=0.23.1->google-cloud-bigquery==0.23.0) (0.11.3)\n",
      "Requirement already satisfied: protobuf>=3.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-core<0.24dev,>=0.23.1->google-cloud-bigquery==0.23.0) (3.13.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-cloud-core<0.24dev,>=0.23.1->google-cloud-bigquery==0.23.0) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-cloud-core<0.24dev,>=0.23.1->google-cloud-bigquery==0.23.0) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.6; python_version < \"3.5\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-cloud-core<0.24dev,>=0.23.1->google-cloud-bigquery==0.23.0) (4.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-cloud-core<0.24dev,>=0.23.1->google-cloud-bigquery==0.23.0) (44.0.0.post20200106)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/envs/py2env/lib/python2.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0.0dev,>=0.4.0->google-cloud-core<0.24dev,>=0.23.1->google-cloud-bigquery==0.23.0) (0.4.8)\n",
      "Installing collected packages: google-cloud-core, google-cloud-bigquery\n",
      "  Found existing installation: google-cloud-core 0.25.0\n",
      "    Uninstalling google-cloud-core-0.25.0:\n",
      "      Successfully uninstalled google-cloud-core-0.25.0\n",
      "  Found existing installation: google-cloud-bigquery 0.25.0\n",
      "    Uninstalling google-cloud-bigquery-0.25.0:\n",
      "      Successfully uninstalled google-cloud-bigquery-0.25.0\n",
      "Successfully installed google-cloud-bigquery-0.23.0 google-cloud-core-0.23.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "apache-airflow 1.9.0 has requirement bleach==2.1.2, but you'll have bleach 1.5.0 which is incompatible.\n",
      "pandas-gbq 0.3.0 has requirement google-cloud-bigquery>=0.28.0, but you'll have google-cloud-bigquery 0.25.0 which is incompatible.\n",
      "googledatastore 7.0.1 has requirement httplib2<0.10,>=0.9.1, but you'll have httplib2 0.11.3 which is incompatible.\n",
      "google-cloud-pubsub 0.26.0 has requirement google-cloud-core<0.26dev,>=0.25.0, but you'll have google-cloud-core 0.23.1 which is incompatible.\n",
      "pandas-gbq 0.3.0 has requirement google-cloud-bigquery>=0.28.0, but you'll have google-cloud-bigquery 0.23.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install --upgrade tensorflow==1.4\n",
    "pip install --ignore-installed --upgrade pytz==2018.4\n",
    "pip uninstall -y google-cloud-dataflow\n",
    "pip install --upgrade apache-beam[gcp]==2.6\n",
    "source activate py2env\n",
    "pip install google-cloud-bigquery==0.23.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'datasetloadexample:sevir' successfully created.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bq mk --dataset datasetloadexample:sevir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'datasetloadexample:sevir.catalog' successfully created.\n",
      "Table 'datasetloadexample:sevir.storm2017' successfully created.\n",
      "Table 'datasetloadexample:sevir.storm2016' successfully created.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bq mk -t sevir.catalog \\\n",
    "id:STRING,file_name:STRING,file_index:INTEGER,img_type:STRING,time_utc:DATETIME,episode_id:STRING,event_id:STRING,event_type:STRING,llcrnrlat:FLOAT,llcrnrlon:FLOAT,urcrnrlat:FLOAT,urcrnrlon:FLOAT,proj:STRING,size_x:INTEGER,size_y:INTEGER,height_m:FLOAT,width_m:FLOAT,data_min:FLOAT,data_max:FLOAT,pct_missing:FLOAT\n",
    "bq mk -t sevir.StormEvents_Details_2019 \\\n",
    "BEGIN_YEARMONTH:INTEGER,BEGIN_DAY:INTEGER,BEGIN_TIME:INTEGER,END_YEARMONTH:INTEGER,END_DAY:INTEGER,END_TIME:INTEGER,EPISODE_ID:INTEGER,EVENT_ID:INTEGER,STATE:STRING,STATE_FIPS:INTEGER,YEAR:INTEGER,MONTH_NAME:STRING,EVENT_TYPE:STRING,CZ_TYPE:STRING,CZ_FIPS:INTEGER,CZ_NAME:STRING,WFO:STRING,BEGIN_DATE_TIME:STRING,CZ_TIMEZONE:STRING,END_DATE_TIME:STRING,INJURIES_DIRECT:STRING,INJURIES_INDIRECT:STRING,DEATHS_DIRECT:STRING,DEATHS_INDIRECT:STRING,DAMAGE_PROPERTY:STRING,DAMAGE_CROPS:STRING,SOURCE:STRING,MAGNITUDE:STRING,MAGNITUDE_TYPE:STRING,FLOOD_CAUSE:STRING,CATEGORY:STRING,BEGIN_RANGE:STRING,BEGIN_AZIMUTH:STRING,BEGIN_LOCATION:STRING,END_RANGE:STRING,END_AZIMUTH:STRING,END_LOCATION:STRING,BEGIN_LAT:STRING,BEGIN_LON:STRING,END_LAT:STRING,END_LON:STRING,EPISODE_NARRATIVE:STRING,EVENT_NARRATIVE:STRING,DATA_SOURCE:STRING\n",
    "bq mk -t sevir.StormEvents_Details_2018 \\\n",
    "BEGIN_YEARMONTH:INTEGER,BEGIN_DAY:INTEGER,BEGIN_TIME:INTEGER,END_YEARMONTH:INTEGER,END_DAY:INTEGER,END_TIME:INTEGER,EPISODE_ID:INTEGER,EVENT_ID:INTEGER,STATE:STRING,STATE_FIPS:INTEGER,YEAR:INTEGER,MONTH_NAME:STRING,EVENT_TYPE:STRING,CZ_TYPE:STRING,CZ_FIPS:INTEGER,CZ_NAME:STRING,WFO:STRING,BEGIN_DATE_TIME:STRING,CZ_TIMEZONE:STRING,END_DATE_TIME:STRING,INJURIES_DIRECT:STRING,INJURIES_INDIRECT:STRING,DEATHS_DIRECT:STRING,DEATHS_INDIRECT:STRING,DAMAGE_PROPERTY:STRING,DAMAGE_CROPS:STRING,SOURCE:STRING,MAGNITUDE:STRING,MAGNITUDE_TYPE:STRING,FLOOD_CAUSE:STRING,CATEGORY:STRING,BEGIN_RANGE:STRING,BEGIN_AZIMUTH:STRING,BEGIN_LOCATION:STRING,END_RANGE:STRING,END_AZIMUTH:STRING,END_LOCATION:STRING,BEGIN_LAT:STRING,BEGIN_LON:STRING,END_LAT:STRING,END_LON:STRING,EPISODE_NARRATIVE:STRING,EVENT_NARRATIVE:STRING,DATA_SOURCE:STRING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'datasetloadexample:sevir.Storm_Combined' successfully created.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bq mk -t sevir.Storm_Combined \\\n",
    "BEGIN_YEARMONTH:INTEGER,BEGIN_DAY:INTEGER,BEGIN_TIME:INTEGER,END_YEARMONTH:INTEGER,END_DAY:INTEGER,END_TIME:INTEGER,EPISODE_ID:INTEGER,EVENT_ID:INTEGER,STATE:STRING,STATE_FIPS:INTEGER,YEAR:INTEGER,MONTH_NAME:STRING,EVENT_TYPE:STRING,CZ_TYPE:STRING,CZ_FIPS:INTEGER,CZ_NAME:STRING,WFO:STRING,BEGIN_DATE_TIME:STRING,CZ_TIMEZONE:STRING,END_DATE_TIME:STRING,INJURIES_DIRECT:STRING,INJURIES_INDIRECT:STRING,DEATHS_DIRECT:STRING,DEATHS_INDIRECT:STRING,DAMAGE_PROPERTY:STRING,DAMAGE_CROPS:STRING,SOURCE:STRING,MAGNITUDE:STRING,MAGNITUDE_TYPE:STRING,FLOOD_CAUSE:STRING,CATEGORY:STRING,BEGIN_RANGE:STRING,BEGIN_AZIMUTH:STRING,BEGIN_LOCATION:STRING,END_RANGE:STRING,END_AZIMUTH:STRING,END_LOCATION:STRING,BEGIN_LAT:STRING,BEGIN_LON:STRING,END_LAT:STRING,END_LON:STRING,EPISODE_NARRATIVE:STRING,EVENT_NARRATIVE:STRING,DATA_SOURCE:STRING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'datasetloadexample:sevir.combined_data' successfully created.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "bq mk -t sevir.combined_data \\\n",
    "ID:STRING,FILE_NAME:STRING,img_type:STRING,EVENT_ID:STRING,EVENT_TYPE:STRING,EPISODE_ID:STRING,BEGIN_YEARMONTH:INTEGER,END_YEARMONTH:INTEGER,STATE:STRING,DEATHS_DIRECT:STRING,FLOOD_CAUSE:STRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "import argparse\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from sys import argv\n",
    "import datetime\n",
    "\n",
    "PROJECT_ID = 'datasetloadexample'\n",
    "#SCHEMA = 'id:STRING,file_name:STRING,file_index:INTEGER,img_type:STRING,time_utc:DATETIME,episode_id:STRING,event_id:STRING,event_type:STRING,llcrnrlat:FLOAT,llcrnrlon:FLOAT,urcrnrlat:FLOAT,urcrnrlon:FLOAT,proj:STRING,size_x:INTEGER,size_y:INTEGER,height_m:FLOAT,width_m:FLOAT,data_min:FLOAT,data_max:FLOAT,pct_missing:FLOAT'\n",
    "\n",
    "def dropcolumns_Catalog(data):\n",
    "  del data['minute_offsets']\n",
    "  return data\n",
    "\n",
    "def convert_types_Catalog(data):\n",
    "  \"\"\"Converts string values to their appropriate type.\"\"\"\n",
    "  data['height_m'] = float(data['height_m']) if 'height_m' in data else None\n",
    "  data['width_m'] = float(data['width_m']) if 'width_m' in data else None\n",
    "  return data\n",
    "\n",
    "def dropcolumns_Storm(data):\n",
    "    del data['CZ_TYPE']\n",
    "    del data['CZ_FIPS']\n",
    "    del data['WFO']\n",
    "    del data['BEGIN_DATE_TIME']\n",
    "    del data['CZ_TIMEZONE']\n",
    "    del data['END_DATE_TIME']\n",
    "    del data['DAMAGE_PROPERTY']\n",
    "    del data['DAMAGE_CROPS']\n",
    "    del data['TOR_F_SCALE']\n",
    "    del data['TOR_LENGTH']\n",
    "    del data['TOR_WIDTH']\n",
    "    del data['TOR_OTHER_WFO']\n",
    "    del data['TOR_OTHER_CZ_STATE']\n",
    "    del data['TOR_OTHER_CZ_FIPS']\n",
    "    del data['TOR_OTHER_CZ_NAME']\n",
    "    del data['END_LON']\n",
    "    del data['EPISODE_NARRATIVE']\n",
    "    del data['EVENT_NARRATIVE']\n",
    "    del data['DATA_SOURCE']\n",
    "    del data['BEGIN_RANGE']\n",
    "    del data['BEGIN_AZIMUTH']\n",
    "    del data['END_RANGE']\n",
    "    del data['END_AZIMUTH']\n",
    "    del data['BEGIN_LAT']\n",
    "    del data['BEGIN_LON']\n",
    "    del data['END_LAT']\n",
    "    return data\n",
    "  \n",
    "def convert_types_Storm(data):\n",
    "  \"\"\"Converts string values to their appropriate type.\"\"\"\n",
    "  data['EVENT_ID'] = int(data['EVENT_ID']) if 'EVENT_ID' in data else None\n",
    "  #data['EPISODE_ID'] = int(data['EPISODE_ID']) if 'EPISODE_ID' in data else None\n",
    "  #data['DEATHS'] = int(data['DEATHS']) if 'DEATHS' in data else None\n",
    "  return data\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "      BEGIN_YEARMONTH,BEGIN_DAY,BEGIN_TIME,END_YEARMONTH,END_DAY,END_TIME,EPISODE_ID,EVENT_ID,STATE,STATE_FIPS,YEAR,MONTH_NAME,EVENT_TYPE,CZ_NAME,INJURIES_DIRECT,INJURIES_INDIRECT,DEATHS_DIRECT,DEATHS_INDIRECT,SOURCE,MAGNITUDE,MAGNITUDE_TYPE,FLOOD_CAUSE,CATEGORY,BEGIN_LOCATION,END_LOCATION\n",
    " FROM `sevir.storm2016`  \n",
    "UNION ALL\n",
    "SELECT \n",
    "      BEGIN_YEARMONTH,BEGIN_DAY,BEGIN_TIME,END_YEARMONTH,END_DAY,END_TIME,EPISODE_ID,EVENT_ID,STATE,STATE_FIPS,YEAR,MONTH_NAME,EVENT_TYPE,CZ_NAME,INJURIES_DIRECT,INJURIES_INDIRECT,DEATHS_DIRECT,DEATHS_INDIRECT,SOURCE,MAGNITUDE,MAGNITUDE_TYPE,FLOOD_CAUSE,CATEGORY,BEGIN_LOCATION,END_LOCATION\n",
    " FROM `sevir.storm2017`\n",
    "    \"\"\"\n",
    "\n",
    "final_query = \"\"\"\n",
    "SELECT s.ID,s.FILE_NAME,s.img_type,s.EVENT_ID,s.EVENT_TYPE,s.EPISODE_ID,d.BEGIN_YEARMONTH, \n",
    "d.END_YEARMONTH, d.STATE,d.DEATHS_DIRECT,d.FLOOD_CAUSE \n",
    "FROM `sevir.catalog` s INNER JOIN  \n",
    "`sevir.storm2017` d \n",
    "ON cast(SUBSTR(s.id,2,15) as numeric) = d.EVENT_ID\n",
    "    \"\"\"\n",
    "\n",
    "p = beam.Pipeline(options=PipelineOptions(flags=argv,\n",
    "runner='DataflowRunner',\n",
    "project='datasetloadexample',\n",
    "job_name='forstormdat'+ '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S'),\n",
    "temp_location='gs://forstormdata/temp',\n",
    "staging_location='gs://forstormdata/tempstg',\n",
    "region='us-central1'))\n",
    "\n",
    "(p | 'ReadCatalog' >> beam.io.ReadFromText('gs://forstormdata/CATALOG.csv', skip_header_lines =1)\n",
    "| 'SplitCatalog' >> beam.Map(lambda x: x.split(','))\n",
    "| 'FormatCatalog' >> beam.Map(lambda x: {\"id\": x[0], \"file_name\": x[1], \"file_index\": x[2],\n",
    "\"img_type\": x[3],\"time_utc\": x[4], \"minute_offsets\": x[5], \"episode_id\": x[6],\n",
    "\"event_id\": x[7], \"event_type\": x[8], \"llcrnrlat\": x[9], \"llcrnrlon\": x[10],\n",
    "\"urcrnrlat\": x[11],\"urcrnrlon\": x[12], \"proj\": x[13], \"size_x\": x[14],\n",
    "\"size_y\": x[15], \"height_m\": x[16], \"width_m\": x[17],\"data_min\": x[18],\n",
    "\"data_max\": x[19], \"pct_missing\": x[20]})\n",
    "| 'PreprocessedCatalog' >> beam.Map(convert_types_Catalog)\n",
    "| 'DroppCatalog' >> beam.Map(dropcolumns_Catalog)\n",
    "| 'WriteToBigQuery-Catalog' >> beam.io.WriteToBigQuery(\n",
    "'{0}:sevir.catalog'.format(PROJECT_ID),\n",
    "schema='id:STRING,file_name:STRING,file_index:INTEGER,img_type:STRING,time_utc:DATETIME,episode_id:STRING,event_id:STRING,event_type:STRING,llcrnrlat:FLOAT,llcrnrlon:FLOAT,urcrnrlat:FLOAT,urcrnrlon:FLOAT,proj:STRING,size_x:INTEGER,size_y:INTEGER,height_m:FLOAT,width_m:FLOAT,data_min:FLOAT,data_max:FLOAT,pct_missing:FLOAT',write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)\n",
    "| 'ReadingFromBucket-Storm2016' >> beam.io.ReadFromText('gs://forstormdata/StormEvents_details-2016.csv', skip_header_lines =1)\n",
    "| 'SplittingCSVData-Storm2016' >> beam.Map(lambda x: x.split(','))\n",
    "| 'FormattingToCSV-Storm2016' >> beam.Map(lambda x: {\"BEGIN_YEARMONTH\":x[0],\"BEGIN_DAY\":x[1],\"BEGIN_TIME\":x[2],\"END_YEARMONTH\":x[3],\"END_DAY\":x[4],\"END_TIME\":x[5],\"EPISODE_ID\":x[6],\"EVENT_ID\":x[7],\"STATE\":x[8],\"STATE_FIPS\":x[9],\"YEAR\":x[10],\"MONTH_NAME\":x[11],\"EVENT_TYPE\":x[12],\"CZ_TYPE\":x[13],\"CZ_FIPS\":x[14],\"CZ_NAME\":x[15],\"WFO\":x[16],\"BEGIN_DATE_TIME\":x[17],\"CZ_TIMEZONE\":x[18],\"END_DATE_TIME\":x[19],\"INJURIES_DIRECT\":x[20],\"INJURIES_INDIRECT\":x[21],\"DEATHS_DIRECT\":x[22],\"DEATHS_INDIRECT\":x[23],\"DAMAGE_PROPERTY\":x[24],\"DAMAGE_CROPS\":x[25],\"SOURCE\":x[26],\"MAGNITUDE\":x[27],\"MAGNITUDE_TYPE\":x[28],\"FLOOD_CAUSE\":x[29],\"CATEGORY\":x[30],\"TOR_F_SCALE\":x[31],\"TOR_LENGTH\":x[32],\"TOR_WIDTH\":x[33],\"TOR_OTHER_WFO\":x[34],\"TOR_OTHER_CZ_STATE\":x[35],\"TOR_OTHER_CZ_FIPS\":x[36],\"TOR_OTHER_CZ_NAME\":x[37],\"BEGIN_RANGE\":x[38],\"BEGIN_AZIMUTH\":x[39],\"BEGIN_LOCATION\":x[40],\"END_RANGE\":x[41],\"END_AZIMUTH\":x[42],\"END_LOCATION\":x[43],\"BEGIN_LAT\":x[44],\"BEGIN_LON\":x[45],\"END_LAT\":x[46],\"END_LON\":x[47],\"EPISODE_NARRATIVE\":x[48],\"EVENT_NARRATIVE\":x[49],\"DATA_SOURCE\":x[50]})\n",
    "| 'PreprocessedData-Storm2016' >> beam.Map(convert_types_Storm)\n",
    "| 'DropColumns-Storm2016' >> beam.Map(dropcolumns_Storm)\n",
    "| 'WriteToBigQuery-Storm2016' >> beam.io.WriteToBigQuery('{0}:sevir.storm2016'.format(PROJECT_ID),\n",
    "             schema='BEGIN_YEARMONTH:INTEGER,BEGIN_DAY:INTEGER,BEGIN_TIME:INTEGER,END_YEARMONTH:INTEGER,END_DAY:INTEGER,END_TIME:INTEGER,EPISODE_ID:INTEGER,EVENT_ID:INTEGER,STATE:STRING,STATE_FIPS:INTEGER,YEAR:INTEGER,MONTH_NAME:STRING,EVENT_TYPE:STRING,CZ_NAME:STRING,INJURIES_DIRECT:STRING,INJURIES_INDIRECT:STRING,DEATHS_DIRECT:STRING,DEATHS_INDIRECT:STRING,SOURCE:STRING,MAGNITUDE:STRING,MAGNITUDE_TYPE:STRING,FLOOD_CAUSE:STRING,CATEGORY:STRING,BEGIN_LOCATION:STRING,END_LOCATION:STRING',\n",
    "             write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)\n",
    " \n",
    "| 'ReadStorm2017' >> beam.io.ReadFromText('gs://forstormdata/StormEvents_details-2017.csv', skip_header_lines =1)\n",
    "| 'SplitStorm2017' >> beam.Map(lambda x: x.split(','))\n",
    "| 'FormatStorm2017' >> beam.Map(lambda x: {\"BEGIN_YEARMONTH\":x[0],\"BEGIN_DAY\":x[1],\"BEGIN_TIME\":x[2],\"END_YEARMONTH\":x[3],\"END_DAY\":x[4],\"END_TIME\":x[5],\"EPISODE_ID\":x[6],\"EVENT_ID\":x[7],\"STATE\":x[8],\"STATE_FIPS\":x[9],\"YEAR\":x[10],\"MONTH_NAME\":x[11],\"EVENT_TYPE\":x[12],\"CZ_TYPE\":x[13],\"CZ_FIPS\":x[14],\"CZ_NAME\":x[15],\"WFO\":x[16],\"BEGIN_DATE_TIME\":x[17],\"CZ_TIMEZONE\":x[18],\"END_DATE_TIME\":x[19],\"INJURIES_DIRECT\":x[20],\"INJURIES_INDIRECT\":x[21],\"DEATHS_DIRECT\":x[22],\"DEATHS_INDIRECT\":x[23],\"DAMAGE_PROPERTY\":x[24],\"DAMAGE_CROPS\":x[25],\"SOURCE\":x[26],\"MAGNITUDE\":x[27],\"MAGNITUDE_TYPE\":x[28],\"FLOOD_CAUSE\":x[29],\"CATEGORY\":x[30],\"TOR_F_SCALE\":x[31],\"TOR_LENGTH\":x[32],\"TOR_WIDTH\":x[33],\"TOR_OTHER_WFO\":x[34],\"TOR_OTHER_CZ_STATE\":x[35],\"TOR_OTHER_CZ_FIPS\":x[36],\"TOR_OTHER_CZ_NAME\":x[37],\"BEGIN_RANGE\":x[38],\"BEGIN_AZIMUTH\":x[39],\"BEGIN_LOCATION\":x[40],\"END_RANGE\":x[41],\"END_AZIMUTH\":x[42],\"END_LOCATION\":x[43],\"BEGIN_LAT\":x[44],\"BEGIN_LON\":x[45],\"END_LAT\":x[46],\"END_LON\":x[47],\"EPISODE_NARRATIVE\":x[48],\"EVENT_NARRATIVE\":x[49],\"DATA_SOURCE\":x[50]})\n",
    "| 'PreprocessedData-Storm2019' >> beam.Map(convert_types_Storm)\n",
    "| 'DropColumns-Storm2017' >> beam.Map(dropcolumns_Storm)\n",
    "| 'WriteToBigQuery-Storm2017' >> beam.io.WriteToBigQuery('{0}:sevir.storm2017'.format(PROJECT_ID),\n",
    "             schema='BEGIN_YEARMONTH:INTEGER,BEGIN_DAY:INTEGER,BEGIN_TIME:INTEGER,END_YEARMONTH:INTEGER,END_DAY:INTEGER,END_TIME:INTEGER,EPISODE_ID:INTEGER,EVENT_ID:INTEGER,STATE:STRING,STATE_FIPS:INTEGER,YEAR:INTEGER,MONTH_NAME:STRING,EVENT_TYPE:STRING,CZ_NAME:STRING,INJURIES_DIRECT:STRING,INJURIES_INDIRECT:STRING,DEATHS_DIRECT:STRING,DEATHS_INDIRECT:STRING,SOURCE:STRING,MAGNITUDE:STRING,MAGNITUDE_TYPE:STRING,FLOOD_CAUSE:STRING,CATEGORY:STRING,BEGIN_LOCATION:STRING,END_LOCATION:STRING',\n",
    "             write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)\n",
    "| 'FetchStormSevirData' >> beam.io.Read(beam.io.BigQuerySource(query=final_query, use_standard_sql=True))\n",
    "| 'WriteCombinedDataToBigQuery' >> beam.io.WriteToBigQuery(\n",
    "           '{0}:sevir.combined_data'.format(PROJECT_ID),schema='ID:STRING,FILE_NAME:STRING,img_type:STRING,EVENT_ID:STRING,EVENT_TYPE:STRING,EPISODE_ID:STRING,BEGIN_YEARMONTH:INTEGER,END_YEARMONTH:INTEGER,STATE:STRING,DEATHS_DIRECT:STRING,FLOOD_CAUSE:STRING',\n",
    "           write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND))\n",
    "\n",
    "result = p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
